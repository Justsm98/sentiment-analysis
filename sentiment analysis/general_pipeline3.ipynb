{"cells":[{"cell_type":"markdown","metadata":{"id":"_a9SvppK5Vtl"},"source":["# General pipeline for project 1\n","This is an example pipeline showing you how to  \n","(1) Load the provided data;  \n","(2) Train models on the train set, and use the validation set to evaluate your model performance;  \n","(3) Generate predictions (pred.csv) on the test set, which is ready for submission."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"0ILgNJU85Vtn","executionInfo":{"status":"ok","timestamp":1680973183315,"user_tz":-480,"elapsed":3682,"user":{"displayName":"Otis WANG","userId":"15804682696362549526"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.pipeline import Pipeline\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n","from sklearn.linear_model import LogisticRegression"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1qVTvoL_biA8","executionInfo":{"status":"ok","timestamp":1680973197264,"user_tz":-480,"elapsed":11413,"user":{"displayName":"Otis WANG","userId":"15804682696362549526"}},"outputId":"9fdc3194-2876-4426-ae24-9a2edff4cdf9"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}],"source":["import os\n","import nltk\n","import math\n","import keras\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from collections import Counter\n","from itertools import chain\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import accuracy_score, f1_score\n","from keras.models import Sequential, Model\n","from keras.layers import Dense, Activation, Embedding, Dropout, BatchNormalization, Input, Add, Concatenate,\\\n","    Bidirectional, SimpleRNN, LSTM, GRU\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","\n","stopwords = set(stopwords.words(\"english\"))\n","ps = PorterStemmer()"]},{"cell_type":"code","source":["#if you use Google Colab, un-comment this cell, modify `path_to_data` if needed, and run to mount data to `data`\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","path_to_data = '/content/drive/MyDrive/Colab Notebooks/COMP4332GP1/data'\n","!rm -f data\n","!ln -s '/content/drive/MyDrive/Colab Notebooks/COMP4332GP1/data' data"],"metadata":{"id":"V9e5rcOs77K9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680973221335,"user_tz":-480,"elapsed":20377,"user":{"displayName":"Otis WANG","userId":"15804682696362549526"}},"outputId":"7838e56e-6d34-4479-9656-bdef4704aeba"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"M1KvPSs65Vto"},"source":["### (1) Loading data\n","The following code shows how to load the datasets for this project.  \n","Among which, we do not release the labels (the \"stars\" column) for the test set. You may evaluate your trained model on the validation set instead.\n","\n","However, your submitted predictions (``pred.csv``) should be generated on the test set."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"wvmtdMvT5Vto","executionInfo":{"status":"ok","timestamp":1680973248893,"user_tz":-480,"elapsed":261,"user":{"displayName":"Otis WANG","userId":"15804682696362549526"}}},"outputs":[],"source":["def load_data(split_name='train', columns=['text', 'stars'], folder='data'):\n","    '''\n","        \"split_name\" may be set as 'train', 'valid' or 'test' to load the corresponding dataset.\n","        \n","        You may also specify the column names to load any columns in the .csv data file.\n","        Among many, \"text\" can be used as model input, and \"stars\" column is the labels (sentiment). \n","        If you like, you are free to use columns other than \"text\" for prediction.\n","    '''\n","    try:\n","        print(f\"select [{', '.join(columns)}] columns from the {split_name} split\")\n","        df = pd.read_csv(f'{folder}/{split_name}.csv')\n","        df = df.loc[:,columns]\n","        print(\"Success\")\n","        return df\n","    except:\n","        print(f\"Failed loading specified columns... Returning all columns from the {split_name} split\")\n","        df = pd.read_csv(f'{folder}/{split_name}.csv')\n","        return df"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uemwLtaB5Vtp","executionInfo":{"status":"ok","timestamp":1680973258544,"user_tz":-480,"elapsed":3118,"user":{"displayName":"Otis WANG","userId":"15804682696362549526"}},"outputId":"da43ca83-2b8d-437f-e4ea-4fd82740d52f"},"outputs":[{"output_type":"stream","name":"stdout","text":["select [text, stars] columns from the train split\n","Success\n","select [text, stars] columns from the valid split\n","Success\n","select [text, stars] columns from the test split\n","Failed loading specified columns... Returning all columns from the test split\n"]}],"source":["train_df = load_data('train', columns=['text', 'stars'])\n","valid_df = load_data('valid', columns=['text', 'stars'])\n","# the test set labels (the 'stars' column) are not available! So the following code will instead return all columns\n","test_df = load_data('test', columns=['text', 'stars'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"YtFQUJuT5Vtq","executionInfo":{"status":"ok","timestamp":1680853643848,"user_tz":-480,"elapsed":266,"user":{"displayName":"Otis WANG","userId":"15804682696362549526"}},"outputId":"000acf85-5672-4a6f-fcf0-e56d33dbec7e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                 business_id  cool                 date  funny  \\\n","0     V-qDa2kr5qWdhs7PU-l-3Q     0           2013-05-29      0   \n","1     C1zlvNlxlGZB8g0162QslQ     0  2012-03-02 15:51:49      0   \n","2     0FOON_PNvG0ZxIZh6Jcv2A     0  2013-09-24 20:31:37      0   \n","3     r49iBfbnfoK7yt4rdsL_7g     0  2018-10-20 01:34:08      0   \n","4     xnLNPkL7bbdhD842T4oPqg     0           2016-09-25      1   \n","...                      ...   ...                  ...    ...   \n","3995  x_0Vf8AVBk_auLnNHRjoVA     2  2013-05-18 03:06:21      0   \n","3996  KAJAsjVhYUPb6b_yodVqvA     0  2018-05-06 05:33:47      0   \n","3997  EnKpL0rRg1MTTKncmxbnMA     0  2012-03-21 20:49:25      0   \n","3998  -NR4KqS6lHseNvJ-GFzfMA     2           2016-08-14      1   \n","3999  kkQxwd2nVlHs1C4fdoAxOg     0  2017-08-03 03:16:49      0   \n","\n","                   review_id  \\\n","0     fBHWLNEJmhk6AkzmfLwWcw   \n","1     ldEQ02aP1OeSa5N2beseNg   \n","2     0oGr6v9VjtRsRsROGMoWTA   \n","3     eg5eJ5HmqXuzkxucnKvMTw   \n","4     BNDAe34Mxj--Brkzcfi4QA   \n","...                      ...   \n","3995  s7FLCfjgopRM6olA1NSccg   \n","3996  oJUnsu4PpTZz-kCE88-9uQ   \n","3997  celcHgmV26VvtzGdUFsR5w   \n","3998  69yY48SDj-UDCKlGgn-nqg   \n","3999  ZM5BFUmzRpZAjwY8jW2Gzg   \n","\n","                                                   text  useful  \\\n","0     Would like to give this more stars - usually I...       1   \n","1     My wife and I took some friends here after din...       0   \n","2     My husband and I had lunch here for the first ...       0   \n","3     I love coming here with my friends! Great for ...       2   \n","4     Make sure that you double check how much these...       1   \n","...                                                 ...     ...   \n","3995  We live nearby and have stopped by this McDona...       0   \n","3996  It was boring as ever! All Spanish music so I ...       0   \n","3997  Was a long time customer, I was entertaining c...       1   \n","3998  I really like this place! I like how you can t...       2   \n","3999  The most cash back you can get here is $20. I ...       0   \n","\n","                     user_id  \n","0     1pigoFijaHVWGrQl1_tYjw  \n","1     BKWPuPZFcGmgjRFRzoq1pw  \n","2     BYVYXKqNs-vv-N1ZhRMs0g  \n","3     dpzmyNglDMeTgV3T5ylUSQ  \n","4     yk9wx31bfMEe_IXB8Q-ylA  \n","...                      ...  \n","3995  Nf3VduiXhQVZRvM2GiXi-w  \n","3996  T3hk43jr0t7ZK8RPmce4sQ  \n","3997  WFWzzvWM45zTx-EShrVVxw  \n","3998  SS3sFA9ksCT9bjocM3Wbug  \n","3999  o7sVRYWSskPEv9veCYes-g  \n","\n","[4000 rows x 8 columns]"],"text/html":["\n","  <div id=\"df-f767fc1d-7a95-4790-803a-ae93a7f4f0fd\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>business_id</th>\n","      <th>cool</th>\n","      <th>date</th>\n","      <th>funny</th>\n","      <th>review_id</th>\n","      <th>text</th>\n","      <th>useful</th>\n","      <th>user_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>V-qDa2kr5qWdhs7PU-l-3Q</td>\n","      <td>0</td>\n","      <td>2013-05-29</td>\n","      <td>0</td>\n","      <td>fBHWLNEJmhk6AkzmfLwWcw</td>\n","      <td>Would like to give this more stars - usually I...</td>\n","      <td>1</td>\n","      <td>1pigoFijaHVWGrQl1_tYjw</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>C1zlvNlxlGZB8g0162QslQ</td>\n","      <td>0</td>\n","      <td>2012-03-02 15:51:49</td>\n","      <td>0</td>\n","      <td>ldEQ02aP1OeSa5N2beseNg</td>\n","      <td>My wife and I took some friends here after din...</td>\n","      <td>0</td>\n","      <td>BKWPuPZFcGmgjRFRzoq1pw</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0FOON_PNvG0ZxIZh6Jcv2A</td>\n","      <td>0</td>\n","      <td>2013-09-24 20:31:37</td>\n","      <td>0</td>\n","      <td>0oGr6v9VjtRsRsROGMoWTA</td>\n","      <td>My husband and I had lunch here for the first ...</td>\n","      <td>0</td>\n","      <td>BYVYXKqNs-vv-N1ZhRMs0g</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>r49iBfbnfoK7yt4rdsL_7g</td>\n","      <td>0</td>\n","      <td>2018-10-20 01:34:08</td>\n","      <td>0</td>\n","      <td>eg5eJ5HmqXuzkxucnKvMTw</td>\n","      <td>I love coming here with my friends! Great for ...</td>\n","      <td>2</td>\n","      <td>dpzmyNglDMeTgV3T5ylUSQ</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>xnLNPkL7bbdhD842T4oPqg</td>\n","      <td>0</td>\n","      <td>2016-09-25</td>\n","      <td>1</td>\n","      <td>BNDAe34Mxj--Brkzcfi4QA</td>\n","      <td>Make sure that you double check how much these...</td>\n","      <td>1</td>\n","      <td>yk9wx31bfMEe_IXB8Q-ylA</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3995</th>\n","      <td>x_0Vf8AVBk_auLnNHRjoVA</td>\n","      <td>2</td>\n","      <td>2013-05-18 03:06:21</td>\n","      <td>0</td>\n","      <td>s7FLCfjgopRM6olA1NSccg</td>\n","      <td>We live nearby and have stopped by this McDona...</td>\n","      <td>0</td>\n","      <td>Nf3VduiXhQVZRvM2GiXi-w</td>\n","    </tr>\n","    <tr>\n","      <th>3996</th>\n","      <td>KAJAsjVhYUPb6b_yodVqvA</td>\n","      <td>0</td>\n","      <td>2018-05-06 05:33:47</td>\n","      <td>0</td>\n","      <td>oJUnsu4PpTZz-kCE88-9uQ</td>\n","      <td>It was boring as ever! All Spanish music so I ...</td>\n","      <td>0</td>\n","      <td>T3hk43jr0t7ZK8RPmce4sQ</td>\n","    </tr>\n","    <tr>\n","      <th>3997</th>\n","      <td>EnKpL0rRg1MTTKncmxbnMA</td>\n","      <td>0</td>\n","      <td>2012-03-21 20:49:25</td>\n","      <td>0</td>\n","      <td>celcHgmV26VvtzGdUFsR5w</td>\n","      <td>Was a long time customer, I was entertaining c...</td>\n","      <td>1</td>\n","      <td>WFWzzvWM45zTx-EShrVVxw</td>\n","    </tr>\n","    <tr>\n","      <th>3998</th>\n","      <td>-NR4KqS6lHseNvJ-GFzfMA</td>\n","      <td>2</td>\n","      <td>2016-08-14</td>\n","      <td>1</td>\n","      <td>69yY48SDj-UDCKlGgn-nqg</td>\n","      <td>I really like this place! I like how you can t...</td>\n","      <td>2</td>\n","      <td>SS3sFA9ksCT9bjocM3Wbug</td>\n","    </tr>\n","    <tr>\n","      <th>3999</th>\n","      <td>kkQxwd2nVlHs1C4fdoAxOg</td>\n","      <td>0</td>\n","      <td>2017-08-03 03:16:49</td>\n","      <td>0</td>\n","      <td>ZM5BFUmzRpZAjwY8jW2Gzg</td>\n","      <td>The most cash back you can get here is $20. I ...</td>\n","      <td>0</td>\n","      <td>o7sVRYWSskPEv9veCYes-g</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4000 rows × 8 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f767fc1d-7a95-4790-803a-ae93a7f4f0fd')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f767fc1d-7a95-4790-803a-ae93a7f4f0fd button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f767fc1d-7a95-4790-803a-ae93a7f4f0fd');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}],"source":["# test_df.columns\n","# print(train_df.columns)\n","# print(valid_df.columns)\n","# print(test_df.columns)\n","test_df"]},{"cell_type":"markdown","metadata":{"id":"46mmwVay5Vtq"},"source":["### (2) Training and validating \n","The following example shows you how to train your model using the train set, and evaluate on the validation set.  \n","As an example, we only use the text data for training. Feel free to use other columns in your implementation.  \n","\n","The model performance on the validation set can be roughly regarded as your models final performance, so we can use it to search for optimal hyper-parameters."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"sJznqPt65Vtq","executionInfo":{"status":"ok","timestamp":1680973265358,"user_tz":-480,"elapsed":286,"user":{"displayName":"Otis WANG","userId":"15804682696362549526"}}},"outputs":[],"source":["# Prepare the data.\n","# As an example, we only use the text data. \n","x_train = train_df['text']\n","y_train = train_df['stars']\n","  \n","x_valid = valid_df['text']\n","y_valid = valid_df['stars']\n","\n","x_test = test_df['text']"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"dQOoPKavbiA_","executionInfo":{"status":"ok","timestamp":1680973270517,"user_tz":-480,"elapsed":303,"user":{"displayName":"Otis WANG","userId":"15804682696362549526"}}},"outputs":[],"source":["def tokenize(text):\n","    \"\"\"\n","    :param text: a doc with multiple sentences, type: str\n","    return a word list, type: list\n","    e.g.\n","    Input: 'Text mining is to identify useful information.'\n","    Output: ['Text', 'mining', 'is', 'to', 'identify', 'useful', 'information', '.']\n","    \"\"\"\n","    return nltk.word_tokenize(text)\n","\n","def stem(tokens):\n","    \"\"\"\n","    :param tokens: a list of tokens, type: list\n","    return a list of stemmed words, type: list\n","    e.g.\n","    Input: ['Text', 'mining', 'is', 'to', 'identify', 'useful', 'information', '.']\n","    Output: ['text', 'mine', 'is', 'to', 'identifi', 'use', 'inform', '.']\n","    \"\"\"\n","\n","    return [ps.stem(token).lower() for token in tokens]"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"1REwamcTbiBA","executionInfo":{"status":"ok","timestamp":1680973278297,"user_tz":-480,"elapsed":2,"user":{"displayName":"Otis WANG","userId":"15804682696362549526"}}},"outputs":[],"source":["def get_feats_dict(feats, min_freq=-1, max_freq=-1, max_size=-1):\n","    \"\"\"\n","    :param data: a list of features, type: list(list)\n","    :param min_freq: the lowest fequency that the fequency of a feature smaller than it will be filtered out, type: int\n","    :param max_freq: the highest fequency that the fequency of a feature larger than it will be filtered out, type: int\n","    :param max_size: the max size of feature dict, type: int\n","    return a feature dict that maps features to indices, sorted by frequencies\n","    # Counter document: https://docs.python.org/3.6/library/collections.html#collections.Counter\n","    \"\"\"\n","    # count all features\n","    feat_cnt = Counter(feats) # [\"text\", \"text\", \"mine\"] --> {\"text\": 2, \"mine\": 1}\n","    if max_size > 0 and min_freq == -1 and max_freq == -1:\n","        valid_feats = [\"<pad>\", \"<unk>\"] + [f for f, cnt in feat_cnt.most_common(max_size-2)]\n","    else:\n","        valid_feats = [\"<pad>\", \"<unk>\"]\n","        for f, cnt in feat_cnt.most_common():\n","            if (min_freq == -1 or cnt >= min_freq) and \\\n","                (max_freq == -1 or cnt <= max_freq):\n","                valid_feats.append(f)\n","    if max_size > 0 and len(valid_feats) > max_size:\n","        valid_feats = valid_feats[:max_size]\n","    print(\"Size of features:\", len(valid_feats))\n","    \n","    # build a mapping from features to indices\n","    feats_dict = dict(zip(valid_feats, range(len(valid_feats))))\n","    return feats_dict\n","\n","def get_index_vector(feats, feats_dict, max_len):\n","    \"\"\"\n","    :param feats: a list of features, type: list\n","    :param feats_dict: a dict from features to indices, type: dict\n","    :param feats: a list of features, type: list\n","    return a feature vector,\n","    \"\"\"\n","    # initialize the vector as all zeros\n","    vector = np.zeros(max_len, dtype=np.int64)\n","    for i, f in enumerate(feats):\n","        if i == max_len:\n","            break\n","        # get the feature index, return 1 (<unk>) if the feature is not existed\n","        f_idx = feats_dict.get(f, 1)\n","        vector[i] = f_idx\n","    return vector"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"ON0v0rNUbiBB","executionInfo":{"status":"ok","timestamp":1680973284410,"user_tz":-480,"elapsed":2,"user":{"displayName":"Otis WANG","userId":"15804682696362549526"}}},"outputs":[],"source":["def build_RNN(input_length, vocab_size, embedding_size,\n","              hidden_size, output_size,\n","              num_rnn_layers, num_mlp_layers,\n","              rnn_type=\"lstm\",\n","              bidirectional=False,\n","              embedding_matrix=None,\n","              activation=\"tanh\",\n","              dropout_rate=0.0,\n","              batch_norm=False,\n","              l2_reg=0.0,\n","              loss=\"categorical_crossentropy\",\n","              optimizer=\"Adam\",\n","              learning_rate=0.001,\n","              metric=\"accuracy\"):\n","    \"\"\"\n","    :param input_length: the maximum length of sentences, type: int\n","    :param vocab_size: the vacabulary size, type: int\n","    :param embedding_size: the dimension of word representations, type: int\n","    :param hidden_size: the dimension of the hidden states, type: int\n","    :param output_size: the dimension of the prediction, type: int\n","    :param num_rnn_layers: the number of layers of the RNN, type: int\n","    :param num_mlp_layers: the number of layers of the MLP, type: int\n","    :param rnn_type: the type of RNN, type: str\n","    :param bidirectional: whether to use bidirectional rnn, type: bool\n","    :param activation: the activation type, type: str\n","    :param dropout_rate: the probability of dropout, type: float\n","    :param batch_norm: whether to enable batch normalization, type: bool\n","    :param l2_reg: the weight for the L2 regularizer, type: str\n","    :param loss: the training loss, type: str\n","    :param optimizer: the optimizer, type: str\n","    :param learning_rate: the learning rate for the optimizer, type: float\n","    :param metric: the metric, type: str\n","    return a RNN for text classification,\n","    # activation document: https://keras.io/activations/\n","    # dropout document: https://keras.io/layers/core/#dropout\n","    # embedding document: https://keras.io/layers/embeddings/#embedding\n","    # recurrent layers document: https://keras.io/layers/recurrent\n","    # batch normalization document: https://keras.io/layers/normalization/\n","    # losses document: https://keras.io/losses/\n","    # optimizers document: https://keras.io/optimizers/\n","    # metrics document: https://keras.io/metrics/\n","    \"\"\"\n","    x = Input(shape=(input_length,))\n","    \n","    ################################\n","    ###### Word Representation #####\n","    ################################\n","    # word representation layer\n","    if embedding_matrix is not None:\n","        emb = Embedding(input_dim=vocab_size,\n","                        output_dim=embedding_size,\n","                        input_length=input_length,\n","                        embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n","                        trainable=False)(x)\n","    else:\n","        emb = Embedding(input_dim=vocab_size,\n","                        output_dim=embedding_size,\n","                        input_length=input_length,\n","                        embeddings_initializer=keras.initializers.TruncatedNormal(mean=0.0, stddev=0.1, seed=0))(x)\n","    \n","    ################################\n","    ####### Recurrent Layers #######\n","    ################################\n","    # recurrent layers\n","    if rnn_type == \"rnn\":\n","        fn = SimpleRNN\n","    elif rnn_type == \"lstm\":\n","        fn = LSTM\n","    elif rnn_type == \"gru\":\n","        fn = GRU\n","    else:\n","        raise NotImplementedError\n","    h = emb\n","    for i in range(num_rnn_layers):\n","        is_last = (i == num_rnn_layers-1)\n","        if bidirectional:\n","            h = Bidirectional(fn(hidden_size,\n","                                 kernel_initializer=keras.initializers.glorot_uniform(seed=0),\n","                                 recurrent_initializer=keras.initializers.Orthogonal(gain=1.0, seed=0),\n","                                 return_sequences=not is_last))(h)\n","        else:\n","            h = fn(hidden_size,\n","                   kernel_initializer=keras.initializers.glorot_uniform(seed=0),\n","                   recurrent_initializer=keras.initializers.Orthogonal(gain=1.0, seed=0),\n","                   return_sequences=not is_last)(h)\n","        h = Dropout(dropout_rate, seed=0)(h)\n","    \n","    ################################\n","    #### Fully Connected Layers ####\n","    ################################\n","    # multi-layer perceptron\n","    for i in range(num_mlp_layers-1):\n","        new_h = Dense(hidden_size,\n","                      kernel_initializer=keras.initializers.he_normal(seed=0),\n","                      bias_initializer=\"zeros\",\n","                      kernel_regularizer=keras.regularizers.l2(l2_reg))(h)\n","        # add batch normalization layer\n","        if batch_norm:\n","            new_h = BatchNormalization()(new_h)\n","        # add residual connection\n","        if i == 0:\n","            h = new_h\n","        else:\n","            h = Add()([h, new_h])\n","        # add activation\n","        h = Activation(activation)(h)\n","    y = Dense(output_size,\n","              activation=\"softmax\",\n","              kernel_initializer=keras.initializers.he_normal(seed=0),\n","              bias_initializer=\"zeros\")(h)\n","    \n","    # set the loss, the optimizer, and the metric\n","    if optimizer == \"SGD\":\n","        optimizer = keras.optimizers.SGD(lr=learning_rate)\n","    elif optimizer == \"RMSprop\":\n","        optmizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n","    elif optimizer == \"Adam\":\n","        optmizer = keras.optimizers.Adam(learning_rate=learning_rate)\n","    else:\n","        raise NotImplementedError\n","    model = Model(x, y)\n","    model.compile(loss=loss, optimizer=optimizer, metrics=[metric])\n","    \n","    return model"]},{"cell_type":"code","source":["!git clone https://github.com/facebookresearch/fastText.git\n","!cd fastText\n","!pip install . "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CYsr5kMp0WOt","executionInfo":{"status":"ok","timestamp":1680973690256,"user_tz":-480,"elapsed":1802,"user":{"displayName":"Otis WANG","userId":"15804682696362549526"}},"outputId":"1c8217d3-e06c-4e66-959c-1381288a0541"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'fastText' already exists and is not an empty directory.\n","\u001b[31mERROR: Directory '.' is not installable. Neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":[],"metadata":{"id":"pcKb3N6S0WXs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"OGCLbXwM0Way"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"2nQoXhcj0WfF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["min_freq = 3\n","# extract features\n","train_tokens = [tokenize(text) for text in x_train]\n","test_tokens = [tokenize(text) for text in x_valid]\n","\n","train_stemmed = [stem(tokens) for tokens in train_tokens]\n","test_stemmed = [stem(tokens) for tokens in test_tokens]\n","\n","train_feats = train_stemmed\n","test_feats = test_stemmed\n","\n","# build a mapping from features to indices\n","feats_dict = get_feats_dict(\n","    chain.from_iterable(train_feats),\n","    min_freq=min_freq)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dN4fYnj2T9Wa","executionInfo":{"status":"ok","timestamp":1680931575373,"user_tz":-480,"elapsed":47521,"user":{"displayName":"Otis WANG","userId":"15804682696362549526"}},"outputId":"7f13a99b-ccbe-48b9-b90e-9718b40bc529"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Size of features: 12069\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"teYhJPWKbiBD"},"outputs":[],"source":["max_len = 50\n","\n","# build the feats_matrix\n","# convert each example to a index vector, and then stack vectors as a matrix\n","train_feats_matrix = np.vstack(\n","    [get_index_vector(f, feats_dict, max_len) for f in train_feats])\n","test_feats_matrix = np.vstack(\n","    [get_index_vector(f, feats_dict, max_len) for f in test_feats])\n","\n","# convert labels to label_matrix\n","num_classes = max(y_train)\n","# convert each label to a ont-hot vector, and then stack vectors as a matrix\n","train_label_matrix = keras.utils.to_categorical(y_train-1, num_classes=num_classes)\n","test_label_matrix = keras.utils.to_categorical(y_valid-1, num_classes=num_classes)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cJ5UG5kEbiBF","executionInfo":{"status":"ok","timestamp":1680932416218,"user_tz":-480,"elapsed":277145,"user":{"displayName":"Otis WANG","userId":"15804682696362549526"}},"outputId":"d1b73b26-5941-49e5-d515-c39a4dbdc6a6"},"outputs":[{"output_type":"stream","name":"stdout","text":["180/180 [==============================] - 10s 50ms/step - loss: 0.7132 - accuracy: 0.7597\n","20/20 [==============================] - 1s 42ms/step - loss: 1.1830 - accuracy: 0.5735\n","training loss: 0.7132350206375122 training accuracy 0.7597222328186035\n","test loss: 1.1829735040664673 test accuracy 0.5734999775886536\n"]}],"source":["os.makedirs(\"models\", exist_ok=True)\n","model = build_RNN(input_length=max_len, vocab_size=len(feats_dict),\n","                  embedding_size=100, hidden_size=100, output_size=num_classes,\n","                  rnn_type=\"lstm\", num_rnn_layers=1, bidirectional=True, num_mlp_layers=2,\n","                  activation=\"tanh\",\n","                  batch_norm=True,\n","                  l2_reg=0.005, dropout_rate=0.5)\n","checkpointer = keras.callbacks.ModelCheckpoint(\n","    filepath=os.path.join(\"models\", \"weights.hdf5\"),\n","    monitor=\"val_accuracy\",\n","    verbose=0,\n","    save_best_only=True)\n","earlystopping = keras.callbacks.EarlyStopping(\n","    monitor='val_loss',\n","    patience=5,\n","    verbose=0)\n","\n","np.random.seed(0)\n","tf.random.set_seed(0)\n","bilstm_history = model.fit(train_feats_matrix, train_label_matrix,\n","                    validation_split=0.1,\n","                    epochs=100, batch_size=100, verbose=0,\n","                    callbacks=[checkpointer, earlystopping])\n","model = keras.models.load_model(os.path.join(\"models\", \"weights.hdf5\"))\n","\n","train_score = model.evaluate(train_feats_matrix, train_label_matrix,\n","                             batch_size=100)\n","test_score = model.evaluate(test_feats_matrix, test_label_matrix,\n","                            batch_size=100)\n","print(\"training loss:\", train_score[0], \"training accuracy\", train_score[1])\n","print(\"test loss:\", test_score[0], \"test accuracy\", test_score[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qIw2vpHGb30p"},"outputs":[],"source":["max_len = 100\n","\n","# build the feats_matrix\n","# convert each example to a index vector, and then stack vectors as a matrix\n","train_feats_matrix = np.vstack(\n","    [get_index_vector(f, feats_dict, max_len) for f in train_feats])\n","test_feats_matrix = np.vstack(\n","    [get_index_vector(f, feats_dict, max_len) for f in test_feats])\n","\n","# convert labels to label_matrix\n","num_classes = max(y_train)\n","# convert each label to a ont-hot vector, and then stack vectors as a matrix\n","train_label_matrix = keras.utils.to_categorical(y_train-1, num_classes=num_classes)\n","test_label_matrix = keras.utils.to_categorical(y_valid-1, num_classes=num_classes)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680933832635,"user_tz":-480,"elapsed":465124,"user":{"displayName":"Otis WANG","userId":"15804682696362549526"}},"outputId":"1356f80f-4dab-418e-de23-726fec661f54","id":"NsLq1cTNakvL"},"outputs":[{"output_type":"stream","name":"stdout","text":["180/180 [==============================] - 17s 89ms/step - loss: 1.1092 - accuracy: 0.6494\n","20/20 [==============================] - 2s 83ms/step - loss: 1.2072 - accuracy: 0.5955\n","training loss: 1.109197974205017 training accuracy 0.6494444608688354\n","test loss: 1.2072333097457886 test accuracy 0.5954999923706055\n"]}],"source":["os.makedirs(\"models\", exist_ok=True)\n","model = build_RNN(input_length=max_len, vocab_size=len(feats_dict),\n","                  embedding_size=100, hidden_size=100, output_size=num_classes,\n","                  rnn_type=\"lstm\", num_rnn_layers=1, bidirectional=True, num_mlp_layers=2,\n","                  activation=\"tanh\",\n","                  batch_norm=True,\n","                  l2_reg=0.005, dropout_rate=0.5)\n","checkpointer = keras.callbacks.ModelCheckpoint(\n","    filepath=os.path.join(\"models\", \"weights.hdf5\"),\n","    monitor=\"val_accuracy\",\n","    verbose=0,\n","    save_best_only=True)\n","earlystopping = keras.callbacks.EarlyStopping(\n","    monitor='val_loss',\n","    patience=5,\n","    verbose=0)\n","\n","np.random.seed(0)\n","tf.random.set_seed(0)\n","bilstm_history = model.fit(train_feats_matrix, train_label_matrix,\n","                    validation_split=0.1,\n","                    epochs=100, batch_size=100, verbose=0,\n","                    callbacks=[checkpointer, earlystopping])\n","model = keras.models.load_model(os.path.join(\"models\", \"weights.hdf5\"))\n","\n","train_score = model.evaluate(train_feats_matrix, train_label_matrix,\n","                             batch_size=100)\n","test_score = model.evaluate(test_feats_matrix, test_label_matrix,\n","                            batch_size=100)\n","print(\"training loss:\", train_score[0], \"training accuracy\", train_score[1])\n","print(\"test loss:\", test_score[0], \"test accuracy\", test_score[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z7y63NVGeKd5"},"outputs":[],"source":["max_len = 50\n","\n","# build the feats_matrix\n","# convert each example to a index vector, and then stack vectors as a matrix\n","train_feats_matrix = np.vstack(\n","    [get_index_vector(f, feats_dict, max_len) for f in train_feats])\n","test_feats_matrix = np.vstack(\n","    [get_index_vector(f, feats_dict, max_len) for f in test_feats])\n","\n","# convert labels to label_matrix\n","num_classes = max(y_train)\n","# convert each label to a ont-hot vector, and then stack vectors as a matrix\n","train_label_matrix = keras.utils.to_categorical(y_train-1, num_classes=num_classes)\n","test_label_matrix = keras.utils.to_categorical(y_valid-1, num_classes=num_classes)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680934532609,"user_tz":-480,"elapsed":532649,"user":{"displayName":"Otis WANG","userId":"15804682696362549526"}},"outputId":"e0b6642b-06fa-41fb-8101-52a9b74a52f8","id":"CQNOuQ4NeOSY"},"outputs":[{"output_type":"stream","name":"stdout","text":["180/180 [==============================] - 21s 110ms/step - loss: 1.0879 - accuracy: 0.6438\n","20/20 [==============================] - 2s 97ms/step - loss: 1.2213 - accuracy: 0.5870\n","training loss: 1.087857961654663 training accuracy 0.643833339214325\n","test loss: 1.2212610244750977 test accuracy 0.5870000123977661\n"]}],"source":["os.makedirs(\"models\", exist_ok=True)\n","model = build_RNN(input_length=max_len, vocab_size=len(feats_dict),\n","                  embedding_size=100, hidden_size=100, output_size=num_classes,\n","                  rnn_type=\"lstm\", num_rnn_layers=2, bidirectional=True, num_mlp_layers=2,\n","                  activation=\"tanh\",\n","                  batch_norm=True,\n","                  l2_reg=0.005, dropout_rate=0.5)\n","checkpointer = keras.callbacks.ModelCheckpoint(\n","    filepath=os.path.join(\"models\", \"weights.hdf5\"),\n","    monitor=\"val_accuracy\",\n","    verbose=0,\n","    save_best_only=True)\n","earlystopping = keras.callbacks.EarlyStopping(\n","    monitor='val_loss',\n","    patience=5,\n","    verbose=0)\n","\n","np.random.seed(0)\n","tf.random.set_seed(0)\n","bilstm_history = model.fit(train_feats_matrix, train_label_matrix,\n","                    validation_split=0.1,\n","                    epochs=100, batch_size=100, verbose=0,\n","                    callbacks=[checkpointer, earlystopping])\n","model = keras.models.load_model(os.path.join(\"models\", \"weights.hdf5\"))\n","\n","train_score = model.evaluate(train_feats_matrix, train_label_matrix,\n","                             batch_size=100)\n","test_score = model.evaluate(test_feats_matrix, test_label_matrix,\n","                            batch_size=100)\n","print(\"training loss:\", train_score[0], \"training accuracy\", train_score[1])\n","print(\"test loss:\", test_score[0], \"test accuracy\", test_score[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kbe4b110jING"},"outputs":[],"source":["max_len = 100\n","\n","# build the feats_matrix\n","# convert each example to a index vector, and then stack vectors as a matrix\n","train_feats_matrix = np.vstack(\n","    [get_index_vector(f, feats_dict, max_len) for f in train_feats])\n","test_feats_matrix = np.vstack(\n","    [get_index_vector(f, feats_dict, max_len) for f in test_feats])\n","\n","# convert labels to label_matrix\n","num_classes = max(y_train)\n","# convert each label to a ont-hot vector, and then stack vectors as a matrix\n","train_label_matrix = keras.utils.to_categorical(y_train-1, num_classes=num_classes)\n","test_label_matrix = keras.utils.to_categorical(y_valid-1, num_classes=num_classes)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680936369223,"user_tz":-480,"elapsed":1032945,"user":{"displayName":"Otis WANG","userId":"15804682696362549526"}},"outputId":"747bb0eb-c113-47db-fa4c-05ca88dc858f","id":"2vwQNJS5jaMW"},"outputs":[{"output_type":"stream","name":"stdout","text":["180/180 [==============================] - 38s 205ms/step - loss: 0.9895 - accuracy: 0.6727\n","20/20 [==============================] - 4s 204ms/step - loss: 1.1314 - accuracy: 0.6025\n","training loss: 0.9894858002662659 training accuracy 0.6726666688919067\n","test loss: 1.1314250230789185 test accuracy 0.6025000214576721\n"]}],"source":["os.makedirs(\"models\", exist_ok=True)\n","model = build_RNN(input_length=max_len, vocab_size=len(feats_dict),\n","                  embedding_size=100, hidden_size=100, output_size=num_classes,\n","                  rnn_type=\"lstm\", num_rnn_layers=2, bidirectional=True, num_mlp_layers=2,\n","                  activation=\"tanh\",\n","                  batch_norm=True,\n","                  l2_reg=0.005, dropout_rate=0.5)\n","checkpointer = keras.callbacks.ModelCheckpoint(\n","    filepath=os.path.join(\"models\", \"weights.hdf5\"),\n","    monitor=\"val_accuracy\",\n","    verbose=0,\n","    save_best_only=True)\n","earlystopping = keras.callbacks.EarlyStopping(\n","    monitor='val_loss',\n","    patience=5,\n","    verbose=0)\n","\n","np.random.seed(0)\n","tf.random.set_seed(0)\n","bilstm_history = model.fit(train_feats_matrix, train_label_matrix,\n","                    validation_split=0.1,\n","                    epochs=100, batch_size=100, verbose=0,\n","                    callbacks=[checkpointer, earlystopping])\n","model = keras.models.load_model(os.path.join(\"models\", \"weights.hdf5\"))\n","\n","train_score = model.evaluate(train_feats_matrix, train_label_matrix,\n","                             batch_size=100)\n","test_score = model.evaluate(test_feats_matrix, test_label_matrix,\n","                            batch_size=100)\n","print(\"training loss:\", train_score[0], \"training accuracy\", train_score[1])\n","print(\"test loss:\", test_score[0], \"test accuracy\", test_score[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lo8OHWzus-ma"},"outputs":[],"source":["max_len = 50\n","\n","# build the feats_matrix\n","# convert each example to a index vector, and then stack vectors as a matrix\n","train_feats_matrix = np.vstack(\n","    [get_index_vector(f, feats_dict, max_len) for f in train_feats])\n","test_feats_matrix = np.vstack(\n","    [get_index_vector(f, feats_dict, max_len) for f in test_feats])\n","\n","# convert labels to label_matrix\n","num_classes = max(y_train)\n","# convert each label to a ont-hot vector, and then stack vectors as a matrix\n","train_label_matrix = keras.utils.to_categorical(y_train-1, num_classes=num_classes)\n","test_label_matrix = keras.utils.to_categorical(y_valid-1, num_classes=num_classes)"]},{"cell_type":"code","source":[],"metadata":{"id":"ibtva9ZzT9dR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"BcVBBholT9f8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"MPQtrRHvT9in"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"yxRdzjEaT9k2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"NeCY89MYT9m9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"HNXd_y6hT9pR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ZyGvsXQ1T9sE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xa2ZddrXT-G2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"0IncxbLUT-JZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_lTXsMK3sNYr"},"source":["import os\n","import re\n","from tqdm import tqdm\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K7hxtI4l0SUJ","outputId":"8c95a4c1-1beb-4752-e274-05370c251b49","executionInfo":{"status":"ok","timestamp":1680853820313,"user_tz":-480,"elapsed":4141,"user":{"displayName":"Otis WANG","userId":"15804682696362549526"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["import torch\n","\n","if torch.cuda.is_available():       \n","    device = torch.device(\"cuda\")\n","    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n","    print('Device name:', torch.cuda.get_device_name(0))\n","\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["No GPU available, using the CPU instead.\n"]}]},{"cell_type":"code","source":["!pip install wheel setuptools pip --upgrade"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IbGjICuJ0ig3","executionInfo":{"status":"ok","timestamp":1680855971240,"user_tz":-480,"elapsed":6128,"user":{"displayName":"Otis WANG","userId":"15804682696362549526"}},"outputId":"3655d65e-45fe-423b-f921-431076085069"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (0.40.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (67.6.1)\n","Requirement already satisfied: pip in /usr/local/lib/python3.9/dist-packages (22.0.4)\n","Collecting pip\n","  Downloading pip-23.0.1-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pip\n","  Attempting uninstall: pip\n","    Found existing installation: pip 22.0.4\n","    Uninstalling pip-22.0.4:\n","      Successfully uninstalled pip-22.0.4\n","Successfully installed pip-23.0.1\n"]}]},{"cell_type":"code","metadata":{"id":"uFiv8WGl4p40","outputId":"e6c31fbf-468d-4876-cb71-1de3a013144c","executionInfo":{"status":"ok","timestamp":1680857490874,"user_tz":-480,"elapsed":10335,"user":{"displayName":"Otis WANG","userId":"15804682696362549526"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Installing collected packages: huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.13.4 transformers-4.27.4\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}]},{"cell_type":"code","metadata":{"id":"4L_Rc7l4bgzJ"},"source":["def text_preprocessing(text):\n","    \"\"\"\n","    - Remove entity mentions (eg. '@united')\n","    - Correct errors (eg. '&amp;' to '&')\n","    @param    text (str): a string to be processed.\n","    @return   text (Str): the processed string.\n","    \"\"\"\n","    # Remove '@name'\n","    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n","\n","    # Replace '&amp;' with '&'\n","    text = re.sub(r'&amp;', '&', text)\n","\n","    # Remove trailing whitespace\n","    text = re.sub(r'\\s+', ' ', text).strip()\n","\n","    return text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yDAfbCle59tP","outputId":"f898d632-6cae-4d2a-ac5f-a80e870f0f3b","executionInfo":{"status":"ok","timestamp":1680857502511,"user_tz":-480,"elapsed":3716,"user":{"displayName":"Otis WANG","userId":"15804682696362549526"}},"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["963fd5a8ded74ad9afd607daea66c659","5e1dbe23e41c4b6199162cb6a3dab0aa","683578ad90d743e0a6d5eb2f59409560","33bd5574863c4763a777c84d973635d8","81760d9f4cb14cc0ae61aa1389549b3a","6252cbd6703743baafde8d1f2c4a89a0","1f9503badc0e42cf933751d55ed29541","b416782715d7416fa82d9aab5aa0c727","0c4eae1f927f4d14ad076b3d8e22a809","cabca14d4ba344de94f5c248bb0a9490","c43659256d1249c6b4e30d0bb22d7f5d","94d65fcec34248008d849334dec5d90c","4bd81180136c4031823ed318d510e7b3","72d2b93a707148d49e380065971039a2","2d151301b7c94605ab8601898e4531bf","944dadc91322466c8e0e8a8ed483063d","2db4f9fabf7e44418d92bbd62be5ad6f","e3ccb78d81744da4bdebdcef5354ec22","a770e5400cf943b48381736fb847584c","72978ca2dd684545b8235956af5dbaea","d53d2a0ac8e64a30aca3df0c14cf57b4","5ba342785dc340a781abbb1e5dad7be0","f2433b0c5faf48bd98f8c97c07234c2e","4c090e0eef94468d90ba35fd16e682b1","2c81fa0153d74b75b3b581c839585fa3","187fa63e04a7441bb31a00f9fada2002","5085d9b2594d46e595d339f840ccdfdd","cc0d544b0f3144deb38a6d6c6b05f37b","68a84b6602ed437dbf189669aebe2b51","f78eacf2afde4b638edb79ee5da20dca","d7334315b80343cb96dd0a22848ed424","778bcf0e678b4dc0b24e40ddb59867f2","c7182accde5b4a85999a0521278c5301"]}},"source":["from transformers import BertTokenizer\n","\n","# Load the BERT tokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","\n","# Create a function to tokenize a set of texts\n","def preprocessing_for_bert(data):\n","    \"\"\"Perform required preprocessing steps for pretrained BERT.\n","    @param    data (np.array): Array of texts to be processed.\n","    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n","    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n","                  tokens should be attended to by the model.\n","    \"\"\"\n","    # Create empty lists to store outputs\n","    input_ids = []\n","    attention_masks = []\n","\n","    # For every sentence...\n","    for sent in data:\n","        # `encode_plus` will:\n","        #    (1) Tokenize the sentence\n","        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n","        #    (3) Truncate/Pad sentence to max length\n","        #    (4) Map tokens to their IDs\n","        #    (5) Create attention mask\n","        #    (6) Return a dictionary of outputs\n","        encoded_sent = tokenizer.encode_plus(\n","            text=text_preprocessing(sent),  # Preprocess sentence\n","            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n","            max_length=MAX_LEN,                  # Max length to truncate/pad\n","            pad_to_max_length=True,         # Pad sentence to max length\n","            #return_tensors='pt',           # Return PyTorch tensor\n","            return_attention_mask=True      # Return attention mask\n","            )\n","        \n","        # Add the outputs to the lists\n","        input_ids.append(encoded_sent.get('input_ids'))\n","        attention_masks.append(encoded_sent.get('attention_mask'))\n","\n","    # Convert lists to tensors\n","    input_ids = torch.tensor(input_ids)\n","    attention_masks = torch.tensor(attention_masks)\n","\n","    return input_ids, attention_masks"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"963fd5a8ded74ad9afd607daea66c659"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94d65fcec34248008d849334dec5d90c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2433b0c5faf48bd98f8c97c07234c2e"}},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"hrbvKGNAlMtt","outputId":"af0f8ea8-b456-40aa-f24a-4e6ce1db200d","executionInfo":{"status":"ok","timestamp":1680858861539,"user_tz":-480,"elapsed":73295,"user":{"displayName":"Otis WANG","userId":"15804682696362549526"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["# Concatenate train data and test data\n","all_data = np.concatenate([x_train, x_valid, x_test])\n","\n","# Encode our concatenated data\n","encoded_data = [tokenizer.encode(sent, add_special_tokens=True) for sent in all_data]\n","\n","# Find the maximum length\n","max_len = max([len(sent) for sent in encoded_data])\n","print('Max length: ', max_len)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Max length:  1265\n"]}]},{"cell_type":"code","metadata":{"id":"QTlQzTzAfCy7","outputId":"eaef9450-9d7e-473d-e544-b0c01b4d4d03","executionInfo":{"status":"ok","timestamp":1680858938602,"user_tz":-480,"elapsed":67993,"user":{"displayName":"Otis WANG","userId":"15804682696362549526"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["# Specify `MAX_LEN`\n","MAX_LEN = 1265\n","\n","# Run function `preprocessing_for_bert` on the train set and the validation set\n","print('Tokenizing data...')\n","train_inputs, train_masks = preprocessing_for_bert(x_train)\n","val_inputs, val_masks = preprocessing_for_bert(x_valid)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenizing data...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]}]},{"cell_type":"code","metadata":{"id":"xHuYEc61gcGL"},"source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","# Convert other data types to torch.Tensor\n","train_labels = torch.tensor(y_train)\n","val_labels = torch.tensor(y_valid)\n","\n","# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n","batch_size = 32\n","\n","# Create the DataLoader for our training set\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","# Create the DataLoader for our validation set\n","val_data = TensorDataset(val_inputs, val_masks, val_labels)\n","val_sampler = SequentialSampler(val_data)\n","val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YK41aBFSj5jK","outputId":"045ffa0b-266d-4629-8515-14671237e647","executionInfo":{"status":"ok","timestamp":1680858673562,"user_tz":-480,"elapsed":227,"user":{"displayName":"Otis WANG","userId":"15804682696362549526"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["%%time\n","import torch\n","import torch.nn as nn\n","from transformers import BertModel\n","\n","# Create the BertClassfier class\n","class BertClassifier(nn.Module):\n","    \"\"\"Bert Model for Classification Tasks.\n","    \"\"\"\n","    def __init__(self, freeze_bert=False):\n","        \"\"\"\n","        @param    bert: a BertModel object\n","        @param    classifier: a torch.nn.Module classifier\n","        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n","        \"\"\"\n","        super(BertClassifier, self).__init__()\n","        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n","        D_in, H, D_out = 768, 50, 2\n","\n","        # Instantiate BERT model\n","        self.bert = BertModel.from_pretrained('bert-base-uncased')\n","\n","        # Instantiate an one-layer feed-forward classifier\n","        self.classifier = nn.Sequential(\n","            nn.Linear(D_in, H),\n","            nn.ReLU(),\n","            #nn.Dropout(0.5),\n","            nn.Linear(H, D_out)\n","        )\n","\n","        # Freeze the BERT model\n","        if freeze_bert:\n","            for param in self.bert.parameters():\n","                param.requires_grad = False\n","        \n","    def forward(self, input_ids, attention_mask):\n","        \"\"\"\n","        Feed input to BERT and the classifier to compute logits.\n","        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n","                      max_length)\n","        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n","                      information with shape (batch_size, max_length)\n","        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n","                      num_labels)\n","        \"\"\"\n","        # Feed input to BERT\n","        outputs = self.bert(input_ids=input_ids,\n","                            attention_mask=attention_mask)\n","        \n","        # Extract the last hidden state of the token `[CLS]` for classification task\n","        last_hidden_state_cls = outputs[0][:, 0, :]\n","\n","        # Feed input to classifier to compute logits\n","        logits = self.classifier(last_hidden_state_cls)\n","\n","        return logits"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 60.7 ms, sys: 984 µs, total: 61.6 ms\n","Wall time: 67.6 ms\n"]}]},{"cell_type":"code","metadata":{"id":"JX7su7Q_269U"},"source":["from transformers import AdamW, get_linear_schedule_with_warmup\n","\n","def initialize_model(epochs=4):\n","    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n","    \"\"\"\n","    # Instantiate Bert Classifier\n","    bert_classifier = BertClassifier(freeze_bert=False)\n","\n","    # Tell PyTorch to run the model on GPU\n","    bert_classifier.to(device)\n","\n","    # Create the optimizer\n","    optimizer = AdamW(bert_classifier.parameters(),\n","                      lr=5e-5,    # Default learning rate\n","                      eps=1e-8    # Default epsilon value\n","                      )\n","\n","    # Total number of training steps\n","    total_steps = len(train_dataloader) * epochs\n","\n","    # Set up the learning rate scheduler\n","    scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                num_warmup_steps=0, # Default value\n","                                                num_training_steps=total_steps)\n","    return bert_classifier, optimizer, scheduler"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xy4HkhyECibW"},"source":["import random\n","import time\n","\n","# Specify loss function\n","loss_fn = nn.CrossEntropyLoss()\n","\n","def set_seed(seed_value=42):\n","    \"\"\"Set seed for reproducibility.\n","    \"\"\"\n","    random.seed(seed_value)\n","    np.random.seed(seed_value)\n","    torch.manual_seed(seed_value)\n","    torch.cuda.manual_seed_all(seed_value)\n","\n","def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n","    \"\"\"Train the BertClassifier model.\n","    \"\"\"\n","    # Start training loop\n","    print(\"Start training...\\n\")\n","    for epoch_i in range(epochs):\n","        # =======================================\n","        #               Training\n","        # =======================================\n","        # Print the header of the result table\n","        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n","        print(\"-\"*70)\n","\n","        # Measure the elapsed time of each epoch\n","        t0_epoch, t0_batch = time.time(), time.time()\n","\n","        # Reset tracking variables at the beginning of each epoch\n","        total_loss, batch_loss, batch_counts = 0, 0, 0\n","\n","        # Put the model into the training mode\n","        model.train()\n","\n","        # For each batch of training data...\n","        for step, batch in enumerate(train_dataloader):\n","            batch_counts +=1\n","            # Load batch to GPU\n","            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n","\n","            # Zero out any previously calculated gradients\n","            model.zero_grad()\n","\n","            # Perform a forward pass. This will return logits.\n","            logits = model(b_input_ids, b_attn_mask)\n","\n","            # Compute loss and accumulate the loss values\n","            loss = loss_fn(logits, b_labels)\n","            batch_loss += loss.item()\n","            total_loss += loss.item()\n","\n","            # Perform a backward pass to calculate gradients\n","            loss.backward()\n","\n","            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","            # Update parameters and the learning rate\n","            optimizer.step()\n","            scheduler.step()\n","\n","            # Print the loss values and time elapsed for every 20 batches\n","            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n","                # Calculate time elapsed for 20 batches\n","                time_elapsed = time.time() - t0_batch\n","\n","                # Print training results\n","                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n","\n","                # Reset batch tracking variables\n","                batch_loss, batch_counts = 0, 0\n","                t0_batch = time.time()\n","\n","        # Calculate the average loss over the entire training data\n","        avg_train_loss = total_loss / len(train_dataloader)\n","\n","        print(\"-\"*70)\n","        # =======================================\n","        #               Evaluation\n","        # =======================================\n","        if evaluation == True:\n","            # After the completion of each training epoch, measure the model's performance\n","            # on our validation set.\n","            val_loss, val_accuracy = evaluate(model, val_dataloader)\n","\n","            # Print performance over the entire training data\n","            time_elapsed = time.time() - t0_epoch\n","            \n","            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n","            print(\"-\"*70)\n","        print(\"\\n\")\n","    \n","    print(\"Training complete!\")\n","\n","\n","def evaluate(model, val_dataloader):\n","    \"\"\"After the completion of each training epoch, measure the model's performance\n","    on our validation set.\n","    \"\"\"\n","    # Put the model into the evaluation mode. The dropout layers are disabled during\n","    # the test time.\n","    model.eval()\n","\n","    # Tracking variables\n","    val_accuracy = []\n","    val_loss = []\n","\n","    # For each batch in our validation set...\n","    for batch in val_dataloader:\n","        # Load batch to GPU\n","        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n","\n","        # Compute logits\n","        with torch.no_grad():\n","            logits = model(b_input_ids, b_attn_mask)\n","\n","        # Compute loss\n","        loss = loss_fn(logits, b_labels)\n","        val_loss.append(loss.item())\n","\n","        # Get the predictions\n","        preds = torch.argmax(logits, dim=1).flatten()\n","\n","        # Calculate the accuracy rate\n","        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n","        val_accuracy.append(accuracy)\n","\n","    # Compute the average accuracy and loss over the validation set.\n","    val_loss = np.mean(val_loss)\n","    val_accuracy = np.mean(val_accuracy)\n","\n","    return val_loss, val_accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wfYw7dJ0U0v6","outputId":"9fa2c7d1-6760-46d4-f62e-4fdc54c32265","executionInfo":{"status":"error","timestamp":1680858978085,"user_tz":-480,"elapsed":1382,"user":{"displayName":"Otis WANG","userId":"15804682696362549526"}},"colab":{"base_uri":"https://localhost:8080/","height":574}},"source":["set_seed(42)    # Set seed for reproducibility\n","bert_classifier, optimizer, scheduler = initialize_model(epochs=2)\n","train(bert_classifier, train_dataloader, val_dataloader, epochs=2, evaluation=True)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Start training...\n","\n"," Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n","----------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-38-2578d57f18d0>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mset_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# Set seed for reproducibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbert_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-34-4d87651a4f76>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, val_dataloader, epochs, evaluation)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;31m# Perform a forward pass. This will return logits.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_attn_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;31m# Compute loss and accumulate the loss values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    984\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"token_type_ids\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m                 \u001b[0mbuffered_token_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m                 \u001b[0mbuffered_token_type_ids_expanded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuffered_token_type_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m                 \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuffered_token_type_ids_expanded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (1265) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [32, 1265].  Tensor sizes: [1, 512]"]}]},{"cell_type":"code","source":[],"metadata":{"id":"QPsqJqoxsVj7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"_c8gj82OsVrU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"yLNcndbHsVuX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qu0eYj2GsVw3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"tUJ6IBltsVzX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"SMp34_1hsV29"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"DKRF1LczsV6l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"SAgV-jicsV9Z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fXza8B1B5Vtr"},"source":[" You can use the valid data to choose the hyperparameters.\n","As an example, you can decide which value of C (1 or 100) is better by evaluating on the valid data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lCpqVf9E5Vtr"},"outputs":[],"source":["# build the first linear model with TFIDF feature\n","tfidf = TfidfVectorizer()\n","lr1 = LogisticRegression(C=100)\n","steps = [('tfidf', tfidf),('lr', lr1)]\n","pipe1 = Pipeline(steps)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"-3f_dYKX5Vtr","executionInfo":{"status":"ok","timestamp":1678612113576,"user_tz":-480,"elapsed":17223,"user":{"displayName":"Azir","userId":"14152163960880447733"}},"outputId":"dbda546b-e880-4921-de61-63035052afd7"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]},{"output_type":"execute_result","data":{"text/plain":["Pipeline(steps=[('tfidf', TfidfVectorizer()),\n","                ('lr', LogisticRegression(C=100))])"],"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n","                (&#x27;lr&#x27;, LogisticRegression(C=100))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n","                (&#x27;lr&#x27;, LogisticRegression(C=100))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=100)</pre></div></div></div></div></div></div></div>"]},"metadata":{},"execution_count":8}],"source":["# train the first model\n","pipe1.fit(x_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uLfCUsS75Vts","executionInfo":{"status":"ok","timestamp":1678612114123,"user_tz":-480,"elapsed":555,"user":{"displayName":"Azir","userId":"14152163960880447733"}},"outputId":"76177ff8-20ed-49d4-c404-2f73ced82926"},"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           1       0.73      0.80      0.76       292\n","           2       0.39      0.29      0.34       163\n","           3       0.35      0.36      0.36       232\n","           4       0.43      0.44      0.43       421\n","           5       0.78      0.78      0.78       892\n","\n","    accuracy                           0.62      2000\n","   macro avg       0.54      0.53      0.53      2000\n","weighted avg       0.62      0.62      0.62      2000\n","\n","\n","\n","\n","[[233  30  15   6   8]\n"," [ 48  48  50  10   7]\n"," [ 22  28  83  71  28]\n"," [  6  10  71 184 150]\n"," [ 10   6  16 161 699]]\n","accuracy 0.6235\n"]}],"source":["# validate on the validation set\n","y_pred = pipe1.predict(x_valid)\n","print(classification_report(y_valid, y_pred))\n","print(\"\\n\\n\")\n","print(confusion_matrix(y_valid, y_pred))\n","print('accuracy', np.mean(y_valid == y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FDZCeni05Vts"},"outputs":[],"source":["# build the second linear model with TFIDF feature\n","tfidf = TfidfVectorizer()\n","lr2 = LogisticRegression(C=1)\n","steps = [('tfidf', tfidf),('lr', lr2)]\n","pipe2 = Pipeline(steps)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"CAMxir2t5Vts","executionInfo":{"status":"ok","timestamp":1678612128484,"user_tz":-480,"elapsed":14365,"user":{"displayName":"Azir","userId":"14152163960880447733"}},"outputId":"45d2e0e0-ab01-4817-d611-38f17b289af4"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]},{"output_type":"execute_result","data":{"text/plain":["Pipeline(steps=[('tfidf', TfidfVectorizer()), ('lr', LogisticRegression(C=1))])"],"text/html":["<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;lr&#x27;, LogisticRegression(C=1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;lr&#x27;, LogisticRegression(C=1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1)</pre></div></div></div></div></div></div></div>"]},"metadata":{},"execution_count":11}],"source":["# train the second model\n","pipe2.fit(x_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"colab":{"base_uri":"https://localhost:8080/"},"id":"8S68CnyP5Vtt","executionInfo":{"status":"ok","timestamp":1678612129619,"user_tz":-480,"elapsed":1149,"user":{"displayName":"Azir","userId":"14152163960880447733"}},"outputId":"2e027302-9444-46d2-cb8c-f7afb87a6d0e"},"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           1       0.70      0.84      0.76       292\n","           2       0.47      0.17      0.25       163\n","           3       0.45      0.27      0.34       232\n","           4       0.48      0.48      0.48       421\n","           5       0.75      0.87      0.81       892\n","\n","    accuracy                           0.66      2000\n","   macro avg       0.57      0.53      0.53      2000\n","weighted avg       0.63      0.66      0.63      2000\n","\n","\n","\n","\n","[[245  16   6   7  18]\n"," [ 65  28  39  19  12]\n"," [ 24  14  63  87  44]\n"," [  9   1  28 202 181]\n"," [  7   1   5 104 775]]\n","accuracy 0.6565\n"]}],"source":["# validate on the validation set\n","y_pred = pipe2.predict(x_valid)\n","print(classification_report(y_valid, y_pred))\n","print(\"\\n\\n\")\n","print(confusion_matrix(y_valid, y_pred))\n","print('accuracy', np.mean(y_valid == y_pred))"]},{"cell_type":"markdown","metadata":{"id":"NP3Xo13t5Vtt"},"source":[" We find the second model (pipe2) has higher accuracy, then we use the second model to make predictions on test data. In practice, you may not only focus on the accuracy, but also other metrics (precision, recall, f1), since the label distribution is not always balanced."]},{"cell_type":"markdown","metadata":{"id":"lAcjqi2h5Vtt"},"source":["### (3) Generate predictions on the test set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VaQTnAOg5Vtu"},"outputs":[],"source":["predict_test = pipe2.predict(x_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wCFjyOS45Vtu","executionInfo":{"status":"ok","timestamp":1678612130632,"user_tz":-480,"elapsed":12,"user":{"displayName":"Azir","userId":"14152163960880447733"}},"outputId":"e5e3ccb9-2bb6-4d2e-a7ef-433262fa5e91"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([3, 4, 5, ..., 1, 5, 1])"]},"metadata":{},"execution_count":14}],"source":["predict_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pICWs3Eg5Vtu"},"outputs":[],"source":["# save your model predictions\n","pred_df = pd.DataFrame({'stars': predict_test, 'review_id': test_df['review_id']})\n","pred_df.to_csv('pred.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"n3690neh5Vtu"},"source":[" Then you may (download and) submit the predictions `pred.csv` on the test set. "]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"},"colab":{"provenance":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"963fd5a8ded74ad9afd607daea66c659":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5e1dbe23e41c4b6199162cb6a3dab0aa","IPY_MODEL_683578ad90d743e0a6d5eb2f59409560","IPY_MODEL_33bd5574863c4763a777c84d973635d8"],"layout":"IPY_MODEL_81760d9f4cb14cc0ae61aa1389549b3a"}},"5e1dbe23e41c4b6199162cb6a3dab0aa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6252cbd6703743baafde8d1f2c4a89a0","placeholder":"​","style":"IPY_MODEL_1f9503badc0e42cf933751d55ed29541","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"683578ad90d743e0a6d5eb2f59409560":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b416782715d7416fa82d9aab5aa0c727","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0c4eae1f927f4d14ad076b3d8e22a809","value":231508}},"33bd5574863c4763a777c84d973635d8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cabca14d4ba344de94f5c248bb0a9490","placeholder":"​","style":"IPY_MODEL_c43659256d1249c6b4e30d0bb22d7f5d","value":" 232k/232k [00:00&lt;00:00, 2.69MB/s]"}},"81760d9f4cb14cc0ae61aa1389549b3a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6252cbd6703743baafde8d1f2c4a89a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f9503badc0e42cf933751d55ed29541":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b416782715d7416fa82d9aab5aa0c727":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c4eae1f927f4d14ad076b3d8e22a809":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cabca14d4ba344de94f5c248bb0a9490":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c43659256d1249c6b4e30d0bb22d7f5d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"94d65fcec34248008d849334dec5d90c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4bd81180136c4031823ed318d510e7b3","IPY_MODEL_72d2b93a707148d49e380065971039a2","IPY_MODEL_2d151301b7c94605ab8601898e4531bf"],"layout":"IPY_MODEL_944dadc91322466c8e0e8a8ed483063d"}},"4bd81180136c4031823ed318d510e7b3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2db4f9fabf7e44418d92bbd62be5ad6f","placeholder":"​","style":"IPY_MODEL_e3ccb78d81744da4bdebdcef5354ec22","value":"Downloading (…)okenizer_config.json: 100%"}},"72d2b93a707148d49e380065971039a2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a770e5400cf943b48381736fb847584c","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_72978ca2dd684545b8235956af5dbaea","value":28}},"2d151301b7c94605ab8601898e4531bf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d53d2a0ac8e64a30aca3df0c14cf57b4","placeholder":"​","style":"IPY_MODEL_5ba342785dc340a781abbb1e5dad7be0","value":" 28.0/28.0 [00:00&lt;00:00, 546B/s]"}},"944dadc91322466c8e0e8a8ed483063d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2db4f9fabf7e44418d92bbd62be5ad6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3ccb78d81744da4bdebdcef5354ec22":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a770e5400cf943b48381736fb847584c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72978ca2dd684545b8235956af5dbaea":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d53d2a0ac8e64a30aca3df0c14cf57b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ba342785dc340a781abbb1e5dad7be0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f2433b0c5faf48bd98f8c97c07234c2e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4c090e0eef94468d90ba35fd16e682b1","IPY_MODEL_2c81fa0153d74b75b3b581c839585fa3","IPY_MODEL_187fa63e04a7441bb31a00f9fada2002"],"layout":"IPY_MODEL_5085d9b2594d46e595d339f840ccdfdd"}},"4c090e0eef94468d90ba35fd16e682b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc0d544b0f3144deb38a6d6c6b05f37b","placeholder":"​","style":"IPY_MODEL_68a84b6602ed437dbf189669aebe2b51","value":"Downloading (…)lve/main/config.json: 100%"}},"2c81fa0153d74b75b3b581c839585fa3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f78eacf2afde4b638edb79ee5da20dca","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d7334315b80343cb96dd0a22848ed424","value":570}},"187fa63e04a7441bb31a00f9fada2002":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_778bcf0e678b4dc0b24e40ddb59867f2","placeholder":"​","style":"IPY_MODEL_c7182accde5b4a85999a0521278c5301","value":" 570/570 [00:00&lt;00:00, 7.83kB/s]"}},"5085d9b2594d46e595d339f840ccdfdd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc0d544b0f3144deb38a6d6c6b05f37b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68a84b6602ed437dbf189669aebe2b51":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f78eacf2afde4b638edb79ee5da20dca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7334315b80343cb96dd0a22848ed424":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"778bcf0e678b4dc0b24e40ddb59867f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7182accde5b4a85999a0521278c5301":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}